{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re \n",
    "from functools import reduce  # Importa reduce de functools para combinar datos\n",
    "from wordcloud import WordCloud  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>other_listings</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>description</th>\n",
       "      <th>branding</th>\n",
       "      <th>...</th>\n",
       "      <th>search_promotions</th>\n",
       "      <th>location</th>\n",
       "      <th>rent_to_own</th>\n",
       "      <th>products</th>\n",
       "      <th>virtual_tours</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>primary</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'href': 'https://ap.rdcpix.com/9a76341d092543...</td>\n",
       "      <td>2023-09-28T20:08:52Z</td>\n",
       "      <td>{'agents': [{'office_name': None}], 'id': 'ALA...</td>\n",
       "      <td>['forced_air', 'big_yard', 'farm', 'ranch', 't...</td>\n",
       "      <td>1423-Atkinson-Dr_Anchorage_AK_99504_M72066-31892</td>\n",
       "      <td>{'rdc': [{'listing_id': '2960080461', 'listing...</td>\n",
       "      <td>2023-09-28T20:09:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sqft': 720, 'baths_consolidated': '1', 'lot_...</td>\n",
       "      <td>[{'name': 'EXP Realty South (Branch Office)', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'address': {'postal_code': '99504', 'state': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'products': ['core.agent', 'co_broke'], 'bran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960080e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>for_sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'href': 'https://ap.rdcpix.com/3ee6f071ed96cf...</td>\n",
       "      <td>2023-09-28T19:10:32Z</td>\n",
       "      <td>{'agents': [{'office_name': None}], 'id': 'ALA...</td>\n",
       "      <td>['community_outdoor_space', 'den_or_office', '...</td>\n",
       "      <td>17610-Birchtree-St_Chugiak_AK_99567_M92453-51489</td>\n",
       "      <td>{'rdc': [{'listing_id': '2960077863', 'listing...</td>\n",
       "      <td>2023-09-28T19:11:18Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sqft': 1860, 'baths_consolidated': '2', 'lot...</td>\n",
       "      <td>[{'name': 'RE MAX Dynamic Properties', 'photo'...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'address': {'postal_code': '99567', 'state': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'products': ['core.agent', 'core.broker', 'li...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960078e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>for_sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'href': 'https://ap.rdcpix.com/f4e61be59e935a...</td>\n",
       "      <td>2023-09-28T19:08:29Z</td>\n",
       "      <td>{'agents': [{'office_name': 'Neue Realty Group...</td>\n",
       "      <td>['garage_1_or_more', 'garage_2_or_more', 'big_...</td>\n",
       "      <td>1115-Gav-Way_Anchorage_AK_99504_M71616-89165</td>\n",
       "      <td>{'rdc': [{'listing_id': '2960077191', 'listing...</td>\n",
       "      <td>2023-09-28T18:58:18Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sqft': 1876, 'baths_consolidated': '2', 'lot...</td>\n",
       "      <td>[{'name': 'Real Brokers Anchorage', 'photo': N...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'address': {'postal_code': '99504', 'state': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'products': ['core.agent', 'co_broke'], 'bran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960077e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>for_sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'href': 'https://ap.rdcpix.com/5b9f5fa3f8a71d...</td>\n",
       "      <td>2023-09-28T17:33:39Z</td>\n",
       "      <td>{'agents': [{'office_name': None}, {'office_na...</td>\n",
       "      <td>['city_view', 'community_outdoor_space', 'fire...</td>\n",
       "      <td>6478-Fairweather-Dr-64_Anchorage_AK_99518_M862...</td>\n",
       "      <td>{'rdc': [{'listing_id': '2960073322', 'listing...</td>\n",
       "      <td>2023-09-28T17:34:48Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sqft': 1372, 'baths_consolidated': '2', 'lot...</td>\n",
       "      <td>[{'name': 'Real Estate Brokers Of Alaska', 'ph...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'address': {'postal_code': '99518', 'state': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'products': ['core.agent', 'co_broke'], 'bran...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960073e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>for_sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'href': 'https://ap.rdcpix.com/d131cb6c1aaded...</td>\n",
       "      <td>2023-09-28T18:22:48Z</td>\n",
       "      <td>{'agents': [{'office_name': None}], 'id': 'ALA...</td>\n",
       "      <td>['community_outdoor_space', 'corner_lot', 'den...</td>\n",
       "      <td>1604-Jefferson-Ave_Anchorage_AK_99517_M87448-2...</td>\n",
       "      <td>{'rdc': [{'listing_id': '2960072612', 'listing...</td>\n",
       "      <td>2023-09-28T17:18:23Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'sqft': 1344, 'baths_consolidated': '2', 'lot...</td>\n",
       "      <td>[{'name': 'Herrington and Company, LLC', 'phot...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'address': {'postal_code': '99517', 'state': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'products': ['core.agent', 'core.broker', 'co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960073e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>for_sale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       primary_photo      last_update_date  \\\n",
       "0  {'href': 'https://ap.rdcpix.com/9a76341d092543...  2023-09-28T20:08:52Z   \n",
       "1  {'href': 'https://ap.rdcpix.com/3ee6f071ed96cf...  2023-09-28T19:10:32Z   \n",
       "2  {'href': 'https://ap.rdcpix.com/f4e61be59e935a...  2023-09-28T19:08:29Z   \n",
       "3  {'href': 'https://ap.rdcpix.com/5b9f5fa3f8a71d...  2023-09-28T17:33:39Z   \n",
       "4  {'href': 'https://ap.rdcpix.com/d131cb6c1aaded...  2023-09-28T18:22:48Z   \n",
       "\n",
       "                                              source  \\\n",
       "0  {'agents': [{'office_name': None}], 'id': 'ALA...   \n",
       "1  {'agents': [{'office_name': None}], 'id': 'ALA...   \n",
       "2  {'agents': [{'office_name': 'Neue Realty Group...   \n",
       "3  {'agents': [{'office_name': None}, {'office_na...   \n",
       "4  {'agents': [{'office_name': None}], 'id': 'ALA...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['forced_air', 'big_yard', 'farm', 'ranch', 't...   \n",
       "1  ['community_outdoor_space', 'den_or_office', '...   \n",
       "2  ['garage_1_or_more', 'garage_2_or_more', 'big_...   \n",
       "3  ['city_view', 'community_outdoor_space', 'fire...   \n",
       "4  ['community_outdoor_space', 'corner_lot', 'den...   \n",
       "\n",
       "                                           permalink  \\\n",
       "0   1423-Atkinson-Dr_Anchorage_AK_99504_M72066-31892   \n",
       "1   17610-Birchtree-St_Chugiak_AK_99567_M92453-51489   \n",
       "2       1115-Gav-Way_Anchorage_AK_99504_M71616-89165   \n",
       "3  6478-Fairweather-Dr-64_Anchorage_AK_99518_M862...   \n",
       "4  1604-Jefferson-Ave_Anchorage_AK_99517_M87448-2...   \n",
       "\n",
       "                                      other_listings             list_date  \\\n",
       "0  {'rdc': [{'listing_id': '2960080461', 'listing...  2023-09-28T20:09:21Z   \n",
       "1  {'rdc': [{'listing_id': '2960077863', 'listing...  2023-09-28T19:11:18Z   \n",
       "2  {'rdc': [{'listing_id': '2960077191', 'listing...  2023-09-28T18:58:18Z   \n",
       "3  {'rdc': [{'listing_id': '2960073322', 'listing...  2023-09-28T17:34:48Z   \n",
       "4  {'rdc': [{'listing_id': '2960072612', 'listing...  2023-09-28T17:18:23Z   \n",
       "\n",
       "  open_houses                                        description  \\\n",
       "0         NaN  {'sqft': 720, 'baths_consolidated': '1', 'lot_...   \n",
       "1         NaN  {'sqft': 1860, 'baths_consolidated': '2', 'lot...   \n",
       "2         NaN  {'sqft': 1876, 'baths_consolidated': '2', 'lot...   \n",
       "3         NaN  {'sqft': 1372, 'baths_consolidated': '2', 'lot...   \n",
       "4         NaN  {'sqft': 1344, 'baths_consolidated': '2', 'lot...   \n",
       "\n",
       "                                            branding  ... search_promotions  \\\n",
       "0  [{'name': 'EXP Realty South (Branch Office)', ...  ...               NaN   \n",
       "1  [{'name': 'RE MAX Dynamic Properties', 'photo'...  ...               NaN   \n",
       "2  [{'name': 'Real Brokers Anchorage', 'photo': N...  ...               NaN   \n",
       "3  [{'name': 'Real Estate Brokers Of Alaska', 'ph...  ...               NaN   \n",
       "4  [{'name': 'Herrington and Company, LLC', 'phot...  ...               NaN   \n",
       "\n",
       "                                            location rent_to_own  \\\n",
       "0  {'address': {'postal_code': '99504', 'state': ...         NaN   \n",
       "1  {'address': {'postal_code': '99567', 'state': ...         NaN   \n",
       "2  {'address': {'postal_code': '99504', 'state': ...         NaN   \n",
       "3  {'address': {'postal_code': '99518', 'state': ...         NaN   \n",
       "4  {'address': {'postal_code': '99517', 'state': ...         NaN   \n",
       "\n",
       "                                            products virtual_tours  community  \\\n",
       "0  {'products': ['core.agent', 'co_broke'], 'bran...           NaN        NaN   \n",
       "1  {'products': ['core.agent', 'core.broker', 'li...           NaN        NaN   \n",
       "2  {'products': ['core.agent', 'co_broke'], 'bran...           NaN        NaN   \n",
       "3  {'products': ['core.agent', 'co_broke'], 'bran...           NaN        NaN   \n",
       "4  {'products': ['core.agent', 'core.broker', 'co...           NaN        NaN   \n",
       "\n",
       "     listing_id  price_reduced_amount  primary    status  \n",
       "0  2.960080e+09                   NaN     True  for_sale  \n",
       "1  2.960078e+09                   NaN     True  for_sale  \n",
       "2  2.960077e+09                   NaN     True  for_sale  \n",
       "3  2.960073e+09                   NaN     True  for_sale  \n",
       "4  2.960073e+09                   NaN     True  for_sale  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'Dataset_houses_for_sale.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer el archivo\n",
    "houses_for_sale = pd.read_csv('Dataset_houses_for_sale.csv')\n",
    "\n",
    "#columnas para eliminar con datos que no son relevantes\n",
    "columns_to_drop=['source','permalink','other_listings','open_houses','branding','coming_soon_date','matterport','search_promotions',\n",
    "                 'rent_to_own','products','virtual_tours','community','price_reduced_amount']\n",
    "\n",
    "#eliminar las columas\n",
    "houses_for_sale.drop(columns=columns_to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processor(df, columnas, columna_target):\n",
    "    \"\"\"\n",
    "    Procesa datos de columnas con representaciones de diccionarios.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame que contiene los datos.\n",
    "        columnas (list): Lista de nombres de columnas.\n",
    "        columna_target (str): Nombre de la columna objetivo.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame procesado.\n",
    "    \"\"\"\n",
    "    lista_dics_datos = []  # Inicializa una lista para almacenar datos procesados\n",
    "\n",
    "    # Itera sobre las filas del DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        property_id = row['property_id']  # Extrae el 'property_id'\n",
    "\n",
    "        # Itera sobre los elementos en la columna objetivo\n",
    "        for elemento in row[columna_target]:\n",
    "            if elemento is not None:\n",
    "                try:\n",
    "                    elemento_data = eval(elemento).copy()  # Convierte a diccionario y copia\n",
    "                except:\n",
    "                    elemento_data = elemento.copy()  # Si no se puede evaluar, copia el elemento\n",
    "            else:\n",
    "                elemento_data = {}\n",
    "\n",
    "            elemento_data['property_id'] = property_id  # Agrega 'property_id' al diccionario\n",
    "            lista_dics_datos.append(elemento_data)  # Agrega el diccionario a la lista de datos\n",
    "\n",
    "    # Crea un nuevo DataFrame con los datos procesados\n",
    "    df_limpio = pd.DataFrame(lista_dics_datos, columns=columnas)\n",
    "\n",
    "    # Devuelve el nuevo DataFrame procesado\n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unraveler(df, target_columns):\n",
    "    \"\"\"\n",
    "    Desanida datos y combina los resultados en un DataFrame final.\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame que contiene los datos.\n",
    "        target_columns (list): Lista de nombres de columnas a desanidar.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame desanidado.\n",
    "    \"\"\"\n",
    "    dfs_temporales = []  # Inicializa una lista para almacenar DataFrames temporales\n",
    "\n",
    "    # Itera sobre las columnas a desanidar\n",
    "    for column in target_columns:\n",
    "        df_grouped = df.groupby('property_id')[column].apply(list).reset_index()  # Agrupa y lista por 'property_id'\n",
    "        columns = ['property_id']  # Inicializa la lista de columnas\n",
    "\n",
    "        # Intenta obtener las claves de los diccionarios y agregarlas a las columnas\n",
    "        try:\n",
    "            columns += [x for x in eval(df_grouped[column][0][0]).keys()]\n",
    "        except:\n",
    "            columns += [x for x in (df_grouped[column][0][0]).keys()]\n",
    "\n",
    "        # Aplica la función de procesamiento de datos para desanidar\n",
    "        df_temporal = data_processor(df_grouped, columns, column)\n",
    "        dfs_temporales.append(df_temporal)  # Agrega el DataFrame temporal a la lista\n",
    "\n",
    "    # Combina los DataFrames temporales en uno final\n",
    "    resultado = reduce(lambda left, right: pd.merge(left, right, on='property_id'), dfs_temporales)\n",
    "\n",
    "    # Combina con el DataFrame original por 'property_id'\n",
    "    resultado = pd.merge(resultado, df, on='property_id')\n",
    "\n",
    "    # Devuelve el DataFrame final desanidado\n",
    "    return resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir función para limpiar y transformar los datos\n",
    "def clean_and_transform_data():\n",
    "    # Cargar el conjunto de datos desde un archivo CSV llamado 'Dataset_houses_for_sale.csv'\n",
    "    houses_for_sale = pd.read_csv('Dataset_houses_for_sale.csv')\n",
    "    # Columnas a eliminar del DataFrame 'houses_for_sale'\n",
    "    columns_to_drop = ['source', 'permalink', 'other_listings', 'open_houses', 'branding', 'coming_soon_date',\n",
    "                       'matterport', 'search_promotions', 'rent_to_own', 'products', 'virtual_tours', 'community',\n",
    "                       'price_reduced_amount']\n",
    "    # Eliminar las columnas especificadas del DataFrame 'houses_for_sale'\n",
    "    houses_for_sale.drop(columns=columns_to_drop, inplace=True)\n",
    "    # Agrupar el DataFrame 'houses_for_sale' por 'property_id' y convertir las descripciones a listas\n",
    "    df = houses_for_sale.groupby('property_id')['description'].apply(list).reset_index()\n",
    "    # Obtener las columnas 'property_id' y las claves de las descripciones de la primera fila\n",
    "    columns = ['property_id']\n",
    "    columns += [x for x in eval(df['description'][0][0]).keys()]\n",
    "     # Procesar el DataFrame 'df' con las columnas obtenidas y la descripción\n",
    "    df_temporal = data_processor(df, columns, 'description')\n",
    "    # Combinar los DataFrames 'df_temporal' y 'houses_for_sale' en función de 'property_id'\n",
    "    df_final = pd.merge(df_temporal, houses_for_sale, on='property_id')\n",
    "    # Columnas que se eliminarán del DataFrame 'df_final'\n",
    "    droppable_columns = ['last_update_date', 'description', 'lead_attributes', 'tax_record']\n",
    "    # Eliminar las columnas especificadas del DataFrame 'df_final'\n",
    "    df_final.drop(columns=droppable_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para extraer números de una cadena de texto\n",
    "def extract_numbers(text):\n",
    "    \"\"\"\n",
    "    Esta función utiliza expresiones regulares para encontrar números en una cadena de texto.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Cadena de texto que se va a analizar.\n",
    "\n",
    "    Returns:\n",
    "        str: Números encontrados en la cadena, separados por comas. Si no se encuentran números, retorna NaN.\n",
    "    \"\"\"\n",
    "    numbers_found = re.findall(r'\\d+\\.\\d+|\\d+', str(text))  # Encuentra números en el texto usando una expresión regular\n",
    "    if numbers_found:\n",
    "        return ','.join(numbers_found)  # Devuelve los números encontrados separados por comas\n",
    "    return np.nan  # Si no se encuentran números, devuelve NaN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TOCALACTEOS\\Desktop\\henry\\PROYECTO_FINAL\\airflow\\pruebaautomatizacion.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Aplicar la función extract_numbers a la columna 'baths_consolidated' en df_final\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_final[\u001b[39m'\u001b[39m\u001b[39mbaths_consolidated\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_final[\u001b[39m'\u001b[39m\u001b[39mbaths_consolidated\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(extract_numbers)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Convertir los números extraídos a tipo de datos float\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_final[\u001b[39m'\u001b[39m\u001b[39mbaths_consolidated\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_final[\u001b[39m'\u001b[39m\u001b[39mbaths_consolidated\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mfloat\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicar la función extract_numbers a la columna 'baths_consolidated' en df_final\n",
    "df_final['baths_consolidated'] = df_final['baths_consolidated'].apply(extract_numbers)\n",
    "\n",
    "# Convertir los números extraídos a tipo de datos float\n",
    "df_final['baths_consolidated'] = df_final['baths_consolidated'].apply(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir una cadena de texto en un objeto de fecha\n",
    "def convert_date(text):\n",
    "    \"\"\"\n",
    "    Esta función intenta convertir una cadena de texto en un objeto de fecha.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): Cadena de texto que se intentará convertir a fecha.\n",
    "\n",
    "    Returns:\n",
    "        datetime: Objeto de fecha si la conversión es exitosa, de lo contrario, devuelve NaN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return pd.to_datetime(text, errors='raise')  # Intenta convertir la cadena a fecha\n",
    "    except ValueError:\n",
    "        return np.nan  # Si hay un error en la conversión, devuelve NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TOCALACTEOS\\Desktop\\henry\\PROYECTO_FINAL\\airflow\\pruebaautomatizacion.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Aplicar la función convert_date a la columna 'sold_date' en df_final\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_final[\u001b[39m'\u001b[39m\u001b[39msold_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_final[\u001b[39m'\u001b[39m\u001b[39msold_date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(convert_date)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Filtrar filas donde 'sold_date' no es NaN y guardar en un archivo CSV\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_final[df_final[\u001b[39m'\u001b[39m\u001b[39msold_date\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnotna()]\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mDf_sold_homes_to_train.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_final' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicar la función convert_date a la columna 'sold_date' en df_final\n",
    "df_final['sold_date'] = df_final['sold_date'].apply(convert_date)\n",
    "\n",
    "# Filtrar filas donde 'sold_date' no es NaN y guardar en un archivo CSV\n",
    "df_final[df_final['sold_date'].notna()].to_csv('Df_sold_homes_to_train.csv')\n",
    "\n",
    "# Columnas que se eliminarán del DataFrame 'df_final'\n",
    "columns_to_drop = ['sold_date', 'sold_price', 'name', 'sub_type']\n",
    "\n",
    "# Eliminar las columnas especificadas del DataFrame 'df_final'\n",
    "df_final.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Convertir 'list_date' a una cadena de texto y mantener solo la fecha (parte antes de 'T')\n",
    "df_final['list_date'] = (df_final['list_date'].astype(str).str.split('T')).str[0]\n",
    "\n",
    "# Convertir 'list_date' a fecha usando la función convert_date\n",
    "df_final['list_date'] = df_final['list_date'].apply(convert_date)\n",
    "\n",
    "# Imprimir columnas y sus valores para la tercera fila del DataFrame 'df_final'\n",
    "for column in df_final.columns:\n",
    "    if type(df_final[column][2]) is str:\n",
    "        print(column, df_final[column][2]+'\\n')\n",
    "\n",
    "# Mostrar las primeras filas de ciertas columnas del DataFrame 'df_final'\n",
    "df_final[['primary_photo', 'tags', 'photos', 'flags', 'location']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar una expresión de forma segura\n",
    "def safe_eval(expression):\n",
    "    \"\"\"\n",
    "    Esta función intenta evaluar una expresión de forma segura utilizando eval().\n",
    "\n",
    "    Parameters:\n",
    "        expression (str): Expresión que se intentará evaluar.\n",
    "\n",
    "    Returns:\n",
    "        result: Resultado de la evaluación de la expresión o la expresión original si hay un error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(expression)  # Intenta evaluar la expresión\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        if expression is np.nan:\n",
    "            return expression  # Si la expresión es NaN, devuelve NaN\n",
    "        else:\n",
    "            print(f\"Error en la evaluación: {e}, and was given {expression}\")  # Imprime el error\n",
    "            return expression  # Si hay un error, devuelve la expresión original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aplicar la función safe_eval a la columna 'tags' en df_final\n",
    "df_final['tags'] = df_final['tags'].apply(safe_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener las etiquetas (tags) de una lista\n",
    "def get_tags(lst):\n",
    "    \"\"\"\n",
    "    Esta función toma una lista y devuelve las etiquetas presentes en ella.\n",
    "\n",
    "    Parameters:\n",
    "        lst (list): Lista que contiene etiquetas.\n",
    "\n",
    "    Returns:\n",
    "        list: Lista de etiquetas extraídas.\n",
    "    \"\"\"\n",
    "    my_list = []\n",
    "    try:\n",
    "        for tag in lst:\n",
    "            my_list.append(tag)\n",
    "        return my_list\n",
    "    except:\n",
    "        return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type single_family\n",
      "\n",
      "primary_photo {'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m763238679s-w1024_h768.jpg'}\n",
      "\n",
      "tags ['community_boat_facilities', 'community_golf', 'community_outdoor_space', 'community_security_features', 'den_or_office', 'energy_efficient', 'fireplace', 'golf_course_lot_or_frontage', 'golf_course_view', 'laundry_room', 'pets_allowed', 'recreation_facilities', 'view', 'single_story', 'garage_1_or_more', 'garage_2_or_more', 'garage_3_or_more', 'gourmet_kitchen', 'high_ceiling', 'wine_cellar', 'gated_community', 'clubhouse', 'golf_course', 'views', 'groundscare', 'security']\n",
      "\n",
      "photos [{'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m763238679s-w1024_h768.jpg'}, {'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m3583859794s-w1024_h768.jpg'}]\n",
      "\n",
      "flags {'is_new_construction': None, 'is_subdivision': None, 'is_plan': None, 'is_price_reduced': None, 'is_pending': None, 'is_foreclosure': None, 'is_new_listing': True, 'is_coming_soon': None, 'is_contingent': None}\n",
      "\n",
      "location {'address': {'postal_code': '85383', 'state': 'Arizona', 'coordinate': {'lon': -112.313678, 'lat': 33.763826}, 'city': 'Peoria', 'state_code': 'AZ', 'line': '31010 N 117th Dr'}, 'street_view_url': 'https://maps.googleapis.com/maps/api/streetview?channel=rdc-streetview&client=gme-movesalesinc&location=31010%20N%20117th%20Dr%2C%20Peoria%2C%20AZ%2085383&size=640x480&source=outdoor&signature=UWiFqjBXrMeXn8KQlA5gWBuNatU=', 'county': {'fips_code': '04013', 'name': 'Maricopa'}}\n",
      "\n",
      "status for_sale\n",
      "\n",
      "street_view_url https://maps.googleapis.com/maps/api/streetview?channel=rdc-streetview&client=gme-movesalesinc&location=31010%20N%20117th%20Dr%2C%20Peoria%2C%20AZ%2085383&size=640x480&source=outdoor&signature=UWiFqjBXrMeXn8KQlA5gWBuNatU=\n",
      "\n",
      "type single_family\n",
      "\n",
      "primary_photo {'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m763238679s-w1024_h768.jpg'}\n",
      "\n",
      "photos [{'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m763238679s-w1024_h768.jpg'}, {'href': 'https://ap.rdcpix.com/fd492f6878f09cbe6eda231a8fcceb73l-m3583859794s-w1024_h768.jpg'}]\n",
      "\n",
      "status for_sale\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\TOCALACTEOS\\Desktop\\henry\\PROYECTO_FINAL\\airflow\\pruebaautomatizacion.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=215'>216</a>\u001b[0m     \u001b[39m# Guardar el DataFrame limpio en un archivo CSV\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=216'>217</a>\u001b[0m     df_final\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mhouses_for_sale_limpio.csv\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m clean_and_transform_data()\n",
      "\u001b[1;32mc:\\Users\\TOCALACTEOS\\Desktop\\henry\\PROYECTO_FINAL\\airflow\\pruebaautomatizacion.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=204'>205</a>\u001b[0m df_final \u001b[39m=\u001b[39m unraveler(df_final, columns)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=206'>207</a>\u001b[0m \u001b[39m# Desenrollar la columna 'coordinate' en df_final\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=207'>208</a>\u001b[0m df_final \u001b[39m=\u001b[39m unraveler(df_final, [\u001b[39m'\u001b[39;49m\u001b[39mcoordinate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=209'>210</a>\u001b[0m \u001b[39m# Eliminar columnas no necesarias del DataFrame df_final\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=210'>211</a>\u001b[0m df_final\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mcoordinate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcounty\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maddress\u001b[39m\u001b[39m'\u001b[39m], inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\TOCALACTEOS\\Desktop\\henry\\PROYECTO_FINAL\\airflow\\pruebaautomatizacion.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Itera sobre las columnas a desanidar\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m target_columns:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     df_grouped \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mproperty_id\u001b[39;49m\u001b[39m'\u001b[39;49m)[column]\u001b[39m.\u001b[39;49mapply(\u001b[39mlist\u001b[39;49m)\u001b[39m.\u001b[39mreset_index()  \u001b[39m# Agrupa y lista por 'property_id'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mproperty_id\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# Inicializa la lista de columnas\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/TOCALACTEOS/Desktop/henry/PROYECTO_FINAL/airflow/pruebaautomatizacion.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Intenta obtener las claves de los diccionarios y agregarlas a las columnas\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:216\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m@Appender\u001b[39m(\n\u001b[0;32m    211\u001b[0m     _apply_docs[\u001b[39m\"\u001b[39m\u001b[39mtemplate\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    212\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m, examples\u001b[39m=\u001b[39m_apply_docs[\u001b[39m\"\u001b[39m\u001b[39mseries_examples\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    213\u001b[0m     )\n\u001b[0;32m    214\u001b[0m )\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[1;32m--> 216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1351\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1352\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1353\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_apply_general(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selected_obj)\n\u001b[0;32m   1354\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   1355\u001b[0m         \u001b[39m# gh-20949\u001b[39;00m\n\u001b[0;32m   1356\u001b[0m         \u001b[39m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[39m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m         \u001b[39m# on a string grouper column\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_apply_general(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[1;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_apply_general\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     is_agg: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1375\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   1376\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1377\u001b[0m \u001b[39m    Apply function f in python space\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[39m        data after applying f\u001b[39;00m\n\u001b[0;32m   1401\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1402\u001b[0m     values, mutated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49mapply(f, data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxis)\n\u001b[0;32m   1403\u001b[0m     \u001b[39mif\u001b[39;00m not_indexed_same \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1404\u001b[0m         not_indexed_same \u001b[39m=\u001b[39m mutated\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:762\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[1;34m(self, f, data, axis)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39m# This calls DataSplitter.__iter__\u001b[39;00m\n\u001b[0;32m    760\u001b[0m zipped \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(group_keys, splitter)\n\u001b[1;32m--> 762\u001b[0m \u001b[39mfor\u001b[39;00m key, group \u001b[39min\u001b[39;00m zipped:\n\u001b[0;32m    763\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(group, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m, key)\n\u001b[0;32m    765\u001b[0m     \u001b[39m# group might be modified\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1239\u001b[0m, in \u001b[0;36mDataSplitter.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1236\u001b[0m starts, ends \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mgenerate_slices(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slabels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mngroups)\n\u001b[0;32m   1238\u001b[0m \u001b[39mfor\u001b[39;00m start, end \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(starts, ends):\n\u001b[1;32m-> 1239\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chop(sdata, \u001b[39mslice\u001b[39;49m(start, end))\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:1254\u001b[0m, in \u001b[0;36mSeriesSplitter._chop\u001b[1;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[0;32m   1252\u001b[0m mgr \u001b[39m=\u001b[39m sdata\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mget_slice(slice_obj)\n\u001b[0;32m   1253\u001b[0m ser \u001b[39m=\u001b[39m sdata\u001b[39m.\u001b[39m_constructor(mgr, name\u001b[39m=\u001b[39msdata\u001b[39m.\u001b[39mname, fastpath\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1254\u001b[0m \u001b[39mreturn\u001b[39;00m ser\u001b[39m.\u001b[39;49m__finalize__(sdata, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgroupby\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\TOCALACTEOS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5959\u001b[0m, in \u001b[0;36mNDFrame.__finalize__\u001b[1;34m(self, other, method, **kwargs)\u001b[0m\n\u001b[0;32m   5957\u001b[0m     \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata) \u001b[39m&\u001b[39m \u001b[39mset\u001b[39m(other\u001b[39m.\u001b[39m_metadata):\n\u001b[0;32m   5958\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(name, \u001b[39mstr\u001b[39m)\n\u001b[1;32m-> 5959\u001b[0m         \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, name, \u001b[39mgetattr\u001b[39m(other, name, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m   5961\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mconcat\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   5962\u001b[0m     attrs \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mobjs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mattrs\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inicializar una lista para almacenar las etiquetas\n",
    "tags = []\n",
    "\n",
    "# Iterar sobre el DataFrame 'df_final' y obtener las etiquetas de la columna 'tags'\n",
    "for index, row in df_final.iterrows():\n",
    "    tag = get_tags(row['tags'])\n",
    "    tags += tag\n",
    "\n",
    "# Crear una lista de palabras y un texto uniendo las etiquetas\n",
    "lista_palabras = tags\n",
    "texto = \" \".join(lista_palabras)\n",
    "\n",
    "\n",
    "# Eliminar etiquetas relacionadas con 'garage', 'story' o 'stories' de la lista de etiquetas\n",
    "Start_tags = 0\n",
    "current_tags = 1\n",
    "while Start_tags != current_tags:\n",
    "    Start_tags = len(tags)\n",
    "    for tag in tags:\n",
    "        if 'garage' in tag or 'story' in tag or 'stories' in tag:\n",
    "            tags.remove(tag)\n",
    "    current_tags = len(tags)\n",
    "\n",
    "# Contar y almacenar la cantidad de cada etiqueta única\n",
    "tags_unicos = {}\n",
    "for tag in tags:\n",
    "    if tag not in tags_unicos.keys():\n",
    "        tags_unicos[tag] = tags.count(tag)\n",
    "    else:\n",
    "        tags.remove(tag)\n",
    "\n",
    "# Crear un DataFrame con las 50 etiquetas más comunes\n",
    "top_50_tags = pd.DataFrame(tags_unicos.values(), tags_unicos.keys()).sort_values(by=0, ascending=False).head(50).rename(columns={0: 'count'})\n",
    "\n",
    "# Lista de columnas a considerar\n",
    "columns = ['flags', 'location']\n",
    "\n",
    "# Aplicar la función unraveler para desenrollar las columnas en df_final\n",
    "df_final = unraveler(df_final, columns)\n",
    "\n",
    "# Eliminar columnas no necesarias del DataFrame df_final\n",
    "df_final.drop(columns=['is_new_listing', 'is_pending', 'flags', 'location', \"is_subdivision\"], inplace=True)\n",
    "\n",
    "# Identificar columnas relacionadas con baños y almacenarlas en bath_columns\n",
    "bath_columns = []\n",
    "for column in df_final.columns:\n",
    "    if 'bath' in column:\n",
    "        bath_columns.append(column)\n",
    "\n",
    "# Iterar sobre las columnas relacionadas con baños y mostrar números mayores a 0 en filas con 'baths_consolidated' NaN\n",
    "for column in bath_columns:\n",
    "    for num in df_final[df_final['baths_consolidated'].isna() == True][column]:\n",
    "        if num > 0:\n",
    "            print(num)\n",
    "\n",
    "# Remover 'baths_consolidated' de bath_columns\n",
    "bath_columns.remove('baths_consolidated')\n",
    "\n",
    "# Eliminar las columnas relacionadas con baños que no son 'baths_consolidated' del DataFrame df_final\n",
    "df_final.drop(bath_columns, axis=1, inplace=True)\n",
    "\n",
    "# Renombrar la columna 'baths_consolidated' a 'baths'\n",
    "df_final = df_final.rename(columns={\"baths_consolidated\": \"baths\"})\n",
    "\n",
    "# Imprimir ciertas columnas y sus valores para la tercera fila del DataFrame df_final\n",
    "for column in df_final.columns:\n",
    "    if type(df_final[column][2]) is str:\n",
    "        print(f'{column}', df_final[column][2]+'\\n')\n",
    "\n",
    "# Definir una nueva lista de columnas a considerar\n",
    "columns = ['address', \"county\"]\n",
    "\n",
    "# Aplicar la función unraveler para desenrollar las nuevas columnas en df_final\n",
    "df_final = unraveler(df_final, columns)\n",
    "\n",
    "# Desenrollar la columna 'coordinate' en df_final\n",
    "df_final = unraveler(df_final, ['coordinate'])\n",
    "\n",
    "# Eliminar columnas no necesarias del DataFrame df_final\n",
    "df_final.drop(columns=['coordinate', 'county', 'address'], inplace=True)\n",
    "\n",
    "# Aplicar la función safe_eval a la columna 'photos' en df_final\n",
    "df_final['photos'] = df_final['photos'].apply(safe_eval)\n",
    "\n",
    "# Guardar el DataFrame limpio en un archivo CSV\n",
    "df_final.to_csv('houses_for_sale_limpio.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
